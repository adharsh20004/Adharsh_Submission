{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-06-21T16:43:10.682609Z","iopub.execute_input":"2023-06-21T16:43:10.682950Z","iopub.status.idle":"2023-06-21T16:43:10.717032Z","shell.execute_reply.started":"2023-06-21T16:43:10.682923Z","shell.execute_reply":"2023-06-21T16:43:10.716073Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# for handling imbalancing\nfrom imblearn.under_sampling import NearMiss\nfrom keras.utils import np_utils\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report , confusion_matrix\n\nimport tensorflow as tf\nimport cv2\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import KFold\n\n\nimport keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.wrappers.scikit_learn import KerasClassifier\nfrom tensorflow.keras.optimizers import Adam\nfrom keras.layers import Dense, Conv2D, MaxPool2D, Flatten, Dropout, BatchNormalization\nfrom keras.layers import Dropout\n\n# for learning rate decay\nfrom keras.callbacks import ReduceLROnPlateau\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Conv2D,MaxPooling2D, Flatten, Dropout, BatchNormalization\nfrom tensorflow.keras.optimizers import SGD\n\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"execution":{"iopub.status.busy":"2023-06-21T16:43:10.718866Z","iopub.execute_input":"2023-06-21T16:43:10.719196Z","iopub.status.idle":"2023-06-21T16:43:20.982383Z","shell.execute_reply.started":"2023-06-21T16:43:10.719174Z","shell.execute_reply":"2023-06-21T16:43:20.981311Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Alphabet Recognizer**\n# Problem Statement\nThe input training dataset contains 28x28 pixel 297960 sample handwritten alphabets. It is represented by 784 features(columns) in the input dataset. The input dataset as well contains the target alphabet value (as numbers from 0..25) as a separate column ( in addition to 784 features columns).\n\nThe ask is to train a model and use it to predict handwritten alphabets for a test data set having 74490 sample images.\nAn output csv file is generated for test data set predictions using the best configured model.\n\n","metadata":{}},{"cell_type":"markdown","source":"# Solution Steps\n1. Read Data set\n1. Examine Data set Properties\n1. Inspecting the Dataframe\n1. Data Preparation\n    1. Copy Target Column(Alphabet) values and Remove from Training Data set\n\t1. Validate Training Sample size per Alphabet \n    1. Under sampling of Training dataset to balance class distribution\n    1. Normalize Training dataset\n    1. Reshape Training dataset for CNN Model\n    1. Encode Target Variable\n1. Model based on Dummy Encoded Data set \n    1. Test-Train Split\n    1. Feature Scaling and Initial RFE\n    1. Feature Selection Using RFE\n        1. Model 1 Outcome\n\t\t1. Model 2 Outcome\n\t\t1. Model 3 Outcome\n\t\t1. Model 4 Outcome\n\t\t1. Model 5 Outcome\n\t\t1. Checking VIFs\n\t\t1. Model 6 Outcome\n    1. Model Evaluation\n\t\t1. Prediction and Lead Score assignment\n\t\t1. Metrics based on Confusion Matrix\n\t\t1. ROC and AUC Metrics and Cut off selection\n\t\t1. Redo Prediction based on Selected Cut off\n\t\t1. Redo Metrics based on Confusion Matrix\n\t\t1. Metrics based on Precision and Recall\n\t\t1. Precision and recall tradeoff\n\t\t1. Analysis of Metrics\n    1. Making predictions on the test set and Evaluation\n    1. Analysis of Metrics\n    1. Analysis of Selected Features\n        1. Correlation Analysis\n        1. Numeric Features\n        1. Categorical Dummy Features\n        1. View the Co-efficient of the Selected Model\n        1. Top Positively influencing Features\n        1. Top Negatively influencing Features\n1. Model based on Frequency Encoded Data set \n    1. Test-Train Split\n    1. Feature Scaling and Initial RFE\n\t\t1. Feature Selection Using RFE\n        1. Model 7 Outcome\n\t\t1. Model 8 Outcome\n\t\t1. Checking VIFs\n\t\t1. Model 9 Outcome\n\t\t1. Model 10 Outcome\n    1. Model Evaluation\n\t\t1. Prediction and Lead Score assignment\n\t\t1. Metrics based on Confusion Matrix\n\t\t1. ROC and AUC Metrics and Cut off selection\n\t\t1. Redo Prediction based on Selected Cut off\n\t\t1. Redo Metrics based on Confusion Matrix, Precision Recall\n\t\t1. Precision and recall tradeoff\n\t\t1. Analysis of Metrics\n    1. Making predictions on the test set and Evaluation\n    1. Analysis of Metrics\n    1. Analysis of Selected Features\n        1. Correlation Analysis\n        1. View the Co-efficient of the Selected Model\n        1. Top Positively influencing Features\n        1. Top Negatively influencing Features","metadata":{}},{"cell_type":"markdown","source":"# Read Training Data set","metadata":{}},{"cell_type":"code","source":"df_train = pd.read_csv('/kaggle/input/alphabet/train.csv')","metadata":{"execution":{"iopub.status.busy":"2023-06-21T16:43:20.983489Z","iopub.execute_input":"2023-06-21T16:43:20.984054Z","iopub.status.idle":"2023-06-21T16:43:37.377439Z","shell.execute_reply.started":"2023-06-21T16:43:20.984033Z","shell.execute_reply":"2023-06-21T16:43:37.376775Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Examine Training Dataset Properties","metadata":{}},{"cell_type":"code","source":"#find the rows x columns\ndf_train.shape","metadata":{"execution":{"iopub.status.busy":"2023-06-21T16:43:37.379607Z","iopub.execute_input":"2023-06-21T16:43:37.380042Z","iopub.status.idle":"2023-06-21T16:43:37.386333Z","shell.execute_reply.started":"2023-06-21T16:43:37.380016Z","shell.execute_reply":"2023-06-21T16:43:37.385249Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Inspecting the Dataframe\n","metadata":{}},{"cell_type":"code","source":"#see the first 10 rows\ndf_train.head(10)","metadata":{"execution":{"iopub.status.busy":"2023-06-21T16:43:37.390591Z","iopub.execute_input":"2023-06-21T16:43:37.390942Z","iopub.status.idle":"2023-06-21T16:43:37.429637Z","shell.execute_reply.started":"2023-06-21T16:43:37.390912Z","shell.execute_reply":"2023-06-21T16:43:37.428553Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#see the last 10 rows\ndf_train.tail()","metadata":{"execution":{"iopub.status.busy":"2023-06-21T16:43:37.431126Z","iopub.execute_input":"2023-06-21T16:43:37.431505Z","iopub.status.idle":"2023-06-21T16:43:37.449012Z","shell.execute_reply.started":"2023-06-21T16:43:37.431473Z","shell.execute_reply":"2023-06-21T16:43:37.448080Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Preparation","metadata":{}},{"cell_type":"markdown","source":"  ### Copy Target Column(Alphabet) values and Remove from Training Data set\n","metadata":{}},{"cell_type":"code","source":"#create target variable y for the alphabet dataset\ny_train = df_train['0']\n\n#remove target column from the df_alpha\ndel df_train['0']","metadata":{"execution":{"iopub.status.busy":"2023-06-21T16:43:37.450184Z","iopub.execute_input":"2023-06-21T16:43:37.450536Z","iopub.status.idle":"2023-06-21T16:43:37.460458Z","shell.execute_reply.started":"2023-06-21T16:43:37.450508Z","shell.execute_reply":"2023-06-21T16:43:37.459072Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Rename values\nalphabet_y_train = y_train.replace([0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25], ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M',\n'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z'])\n","metadata":{"execution":{"iopub.status.busy":"2023-06-21T16:43:37.461922Z","iopub.execute_input":"2023-06-21T16:43:37.462184Z","iopub.status.idle":"2023-06-21T16:43:37.541330Z","shell.execute_reply.started":"2023-06-21T16:43:37.462155Z","shell.execute_reply":"2023-06-21T16:43:37.539692Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#view mapping \nalphabet_y_train","metadata":{"execution":{"iopub.status.busy":"2023-06-21T16:43:37.545955Z","iopub.execute_input":"2023-06-21T16:43:37.546233Z","iopub.status.idle":"2023-06-21T16:43:37.559061Z","shell.execute_reply.started":"2023-06-21T16:43:37.546205Z","shell.execute_reply":"2023-06-21T16:43:37.557672Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":" ### Validate Training Sample size per Alphabet ","metadata":{}},{"cell_type":"code","source":"# Looking for imbalances in data\nplt.figure(figsize = (10,5))\nsns.displot(alphabet_y_train)","metadata":{"execution":{"iopub.status.busy":"2023-06-21T16:43:37.560687Z","iopub.execute_input":"2023-06-21T16:43:37.561057Z","iopub.status.idle":"2023-06-21T16:43:38.414508Z","shell.execute_reply.started":"2023-06-21T16:43:37.561019Z","shell.execute_reply":"2023-06-21T16:43:38.413552Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Under sampling of Training dataset to balance class distribution","metadata":{}},{"cell_type":"code","source":"#undersample and balance samples per alphabet equally (~883 images per alphabet as outcome)\nnM = NearMiss()\nX_train_data, y_train_data = nM.fit_resample(df_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2023-06-21T16:43:38.417585Z","iopub.execute_input":"2023-06-21T16:43:38.417860Z","iopub.status.idle":"2023-06-21T16:43:50.939707Z","shell.execute_reply.started":"2023-06-21T16:43:38.417838Z","shell.execute_reply":"2023-06-21T16:43:50.938454Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#visualize the distribution of the class after balancing\nplt.figure(figsize = (10,5))\nsns.displot(y_train_data)","metadata":{"execution":{"iopub.status.busy":"2023-06-21T16:43:50.941024Z","iopub.execute_input":"2023-06-21T16:43:50.941333Z","iopub.status.idle":"2023-06-21T16:43:51.248773Z","shell.execute_reply.started":"2023-06-21T16:43:50.941305Z","shell.execute_reply":"2023-06-21T16:43:51.247733Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#shape of the updated training dataset\ny_train_data.shape , X_train_data.shape","metadata":{"execution":{"iopub.status.busy":"2023-06-21T16:43:51.250027Z","iopub.execute_input":"2023-06-21T16:43:51.250310Z","iopub.status.idle":"2023-06-21T16:43:51.256752Z","shell.execute_reply.started":"2023-06-21T16:43:51.250288Z","shell.execute_reply":"2023-06-21T16:43:51.255705Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"###     Normalize Training dataset\n","metadata":{}},{"cell_type":"code","source":"#normalize the training data set values\nX_train_data = X_train_data / 255\nX_train_data","metadata":{"execution":{"iopub.status.busy":"2023-06-21T16:43:51.258551Z","iopub.execute_input":"2023-06-21T16:43:51.258893Z","iopub.status.idle":"2023-06-21T16:43:51.345869Z","shell.execute_reply.started":"2023-06-21T16:43:51.258865Z","shell.execute_reply":"2023-06-21T16:43:51.344521Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Reshape Training dataset for CNN Model ","metadata":{}},{"cell_type":"code","source":"#reshape datset\nX_train_data = np.array(X_train_data)\nX_train_data = X_train_data.reshape(-1,28,28,1)\n","metadata":{"execution":{"iopub.status.busy":"2023-06-21T16:43:51.347164Z","iopub.execute_input":"2023-06-21T16:43:51.347821Z","iopub.status.idle":"2023-06-21T16:43:55.852388Z","shell.execute_reply.started":"2023-06-21T16:43:51.347792Z","shell.execute_reply":"2023-06-21T16:43:55.851255Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# view some of the handwritten alphabet images\nf, ax = plt.subplots(5,5)\nf.set_size_inches(10,10)\nk = 0\nfor i in range(5):\n    for j in range(5):\n        ax[i,j].imshow(X_train_data[k].reshape(28,28), cmap='gray')\n        k += 1\n    plt.tight_layout()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Encode Target Variable","metadata":{}},{"cell_type":"code","source":"#One-Hot-Encoding of the target.\ny = np_utils.to_categorical(y_train_data)\n# Define the classification of 26 alphabets.\nnum_classes = y.shape[1]\nnum_classes","metadata":{"execution":{"iopub.status.busy":"2023-06-21T16:43:55.853885Z","iopub.execute_input":"2023-06-21T16:43:55.854320Z","iopub.status.idle":"2023-06-21T16:43:55.862815Z","shell.execute_reply.started":"2023-06-21T16:43:55.854294Z","shell.execute_reply":"2023-06-21T16:43:55.861438Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X_train_data, y, test_size=0.2 ,random_state=102)\n","metadata":{"execution":{"iopub.status.busy":"2023-06-21T16:43:55.864181Z","iopub.execute_input":"2023-06-21T16:43:55.864614Z","iopub.status.idle":"2023-06-21T16:43:55.997753Z","shell.execute_reply.started":"2023-06-21T16:43:55.864583Z","shell.execute_reply":"2023-06-21T16:43:55.996705Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train.shape, X_test.shape, y_train.shape, y_test.shape","metadata":{"execution":{"iopub.status.busy":"2023-06-21T16:43:55.999901Z","iopub.execute_input":"2023-06-21T16:43:56.000300Z","iopub.status.idle":"2023-06-21T16:43:56.008694Z","shell.execute_reply.started":"2023-06-21T16:43:56.000265Z","shell.execute_reply":"2023-06-21T16:43:56.006845Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Build an ordinary \"Deep Learning\" model with CNN and maxpooling by using Keras.\nmodel = Sequential()\nmodel.add(Conv2D(32, (5, 5), input_shape=(28, 28, 1), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Flatten())\nmodel.add(Dense(128, activation='relu'))\nmodel.add(Dense(num_classes, activation='softmax'))\n#Choose an optimizer and compile the model.\nmodel.compile(optimizer = Adam(learning_rate = 0.01), loss = 'categorical_crossentropy', metrics = ['accuracy'])\n#And print the summary of the model.\nprint(model.summary())","metadata":{"execution":{"iopub.status.busy":"2023-06-21T16:43:56.010649Z","iopub.execute_input":"2023-06-21T16:43:56.011011Z","iopub.status.idle":"2023-06-21T16:43:56.215078Z","shell.execute_reply.started":"2023-06-21T16:43:56.010982Z","shell.execute_reply":"2023-06-21T16:43:56.214067Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def model_fit_history_plot(history):\n    plt.figure(1)\n    plt.plot(history.history['loss'])\n    plt.plot(history.history['val_loss'])\n    plt.legend(['training','validation'])\n    plt.title('Loss')\n    plt.xlabel('epoch')\n    plt.figure(2)\n    plt.plot(history.history['accuracy'])\n    plt.plot(history.history['val_accuracy'])\n    plt.legend(['training','validation'])\n    plt.title('Accuracy')\n    plt.xlabel('epoch')\n    plt.show()\n    return None","metadata":{"execution":{"iopub.status.busy":"2023-06-21T16:43:56.216277Z","iopub.execute_input":"2023-06-21T16:43:56.216563Z","iopub.status.idle":"2023-06-21T16:43:56.222963Z","shell.execute_reply.started":"2023-06-21T16:43:56.216539Z","shell.execute_reply":"2023-06-21T16:43:56.221704Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#fit the defined model for training / validation data sets\nhistory = model.fit(X_train,y_train,epochs=15, batch_size=128, validation_data=(X_test,y_test))\n\n","metadata":{"execution":{"iopub.status.busy":"2023-06-21T16:43:56.224083Z","iopub.execute_input":"2023-06-21T16:43:56.224360Z","iopub.status.idle":"2023-06-21T16:44:58.544010Z","shell.execute_reply.started":"2023-06-21T16:43:56.224337Z","shell.execute_reply":"2023-06-21T16:44:58.542790Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Final evaluation of the model\nscores = model.evaluate(X_test,y_test, verbose=0)\nprint(\"CNN Error: %.2f%%\" % (100-scores[1]*100))\n\n#Plot fit history\nmodel_fit_history_plot(history)","metadata":{"execution":{"iopub.status.busy":"2023-06-21T16:44:58.545162Z","iopub.execute_input":"2023-06-21T16:44:58.545461Z","iopub.status.idle":"2023-06-21T16:44:59.566815Z","shell.execute_reply.started":"2023-06-21T16:44:58.545440Z","shell.execute_reply":"2023-06-21T16:44:59.565602Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Grid Search to determine the layers and neurons in each layer in the sequential model.\ndef create_model(layers):\n    cnn_model = tf.keras.models.Sequential()\n    cnn_model.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, padding=\"same\", activation=\"relu\", input_shape=[28, 28, 1]))\n    cnn_model.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2, padding='valid'))\n    cnn_model.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, padding=\"same\", activation=\"relu\"))\n    cnn_model.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2, padding='valid'))\n    cnn_model.add(tf.keras.layers.Flatten())\n    \n    for i, nodes in enumerate(layers):\n        cnn_model.add(tf.keras.layers.Dense(units=nodes, activation='relu'))\n            \n    cnn_model.add(tf.keras.layers.Dense(units=26, activation='softmax'))\n    \n    cnn_model.compile(optimizer = 'Adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n    return cnn_model\n\nmodel = KerasClassifier(build_fn=create_model, verbose=1)\nlayers = [[128],(256, 128),(200, 150, 120)]\nparam_grid = dict(layers=layers)\ngrid = GridSearchCV(estimator=model, param_grid=param_grid, verbose=1)\ngrid_results = grid.fit(X_train,y_train, validation_data=(X_test, y_test))\nprint(\"Best: {0}, using {1}\".format(grid_results.best_score_, grid_results.best_params_))\nmeans = grid_results.cv_results_['mean_test_score']\nstds = grid_results.cv_results_['std_test_score']\nparams = grid_results.cv_results_['params']\nfor mean, stdev, param in zip(means, stds, params):\n    print('{0} ({1}) with: {2}'.format(mean, stdev, param))\nbest_layer_size=grid_results.best_params_['layers']  \n    ","metadata":{"execution":{"iopub.status.busy":"2023-06-21T16:44:59.568018Z","iopub.execute_input":"2023-06-21T16:44:59.568287Z","iopub.status.idle":"2023-06-21T16:47:47.562062Z","shell.execute_reply.started":"2023-06-21T16:44:59.568264Z","shell.execute_reply":"2023-06-21T16:47:47.560882Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Grid Search to determine the batch size\ndef create_model1():\n    cnn_model = tf.keras.models.Sequential()\n    cnn_model.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, padding=\"same\", activation=\"relu\", input_shape=[28, 28, 1]))\n    cnn_model.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2, padding='valid'))\n    cnn_model.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, padding=\"same\", activation=\"relu\"))\n    cnn_model.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2, padding='valid'))\n    cnn_model.add(tf.keras.layers.Flatten())\n    cnn_model.add(tf.keras.layers.Dense(units=256, activation='relu'))\n    cnn_model.add(tf.keras.layers.Dense(units=128, activation='relu'))\n    cnn_model.add(tf.keras.layers.Dense(units=26, activation='softmax'))\n    \n    cnn_model.compile(optimizer = 'Adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n    return cnn_model\n\nmodel = KerasClassifier(build_fn = create_model1, verbose = 1)\n\nbatch_size = [15,20,40,50]\nparam_grid = dict(batch_size=batch_size)\n\ngrid = GridSearchCV(estimator = model, param_grid = param_grid, verbose = 1)\ngrid_results = grid.fit(X_train,y_train, validation_data=(X_test, y_test))\n\nprint(\"Best: {0}, using {1}\".format(grid_results.best_score_, grid_results.best_params_))\nmeans = grid_results.cv_results_['mean_test_score']\nparams = grid_results.cv_results_['params']\nfor mean,param in zip(means,params):\n    print('{0} with: {1}'.format(mean,param))\nbest_batch_size=grid_results.best_params_['batch_size']","metadata":{"execution":{"iopub.status.busy":"2023-06-21T16:47:47.563498Z","iopub.execute_input":"2023-06-21T16:47:47.563730Z","iopub.status.idle":"2023-06-21T16:52:45.277026Z","shell.execute_reply.started":"2023-06-21T16:47:47.563708Z","shell.execute_reply":"2023-06-21T16:52:45.275659Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Grid Search to determine the dropout rate\n\ndef create_model2(dropout):\n    # create model\n    cnn_model = tf.keras.models.Sequential()\n    cnn_model.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, padding=\"same\", activation=\"relu\", input_shape=[28, 28, 1]))\n    cnn_model.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2, padding='valid'))\n    cnn_model.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, padding=\"same\", activation=\"relu\"))\n    cnn_model.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2, padding='valid'))\n    cnn_model.add(tf.keras.layers.Flatten())\n    cnn_model.add(tf.keras.layers.Dense(units=best_layer_size[0], activation='relu'))\n    cnn_model.add(Dropout(dropout))\n    cnn_model.add(tf.keras.layers.Dense(units=best_layer_size[1], activation='relu'))\n    cnn_model.add(Dropout(dropout))\n    cnn_model.add(tf.keras.layers.Dense(units=26, activation='softmax'))\n    \n    cnn_model.compile(optimizer = 'Adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n    return cnn_model\n\nmodel = KerasClassifier(build_fn = create_model2, verbose = 1, batch_size=best_batch_size)\n\ndropout = [0.0, 0.1, 0.2]\nparam_grid = dict(dropout=dropout)\n\ngrid = GridSearchCV(estimator = model, param_grid = param_grid, verbose = 1)\ngrid_results = grid.fit(X_train,y_train, validation_data=(X_test, y_test))\n\nprint(\"Best: {0}, using {1}\".format(grid_results.best_score_, grid_results.best_params_))\nmeans = grid_results.cv_results_['mean_test_score']\nparams = grid_results.cv_results_['params']\nfor mean,param in zip(means,params):\n    print('{0} with: {1}'.format(mean,param))\nbest_dropout_rate=grid_results.best_params_['dropout']","metadata":{"execution":{"iopub.status.busy":"2023-06-21T16:52:45.278451Z","iopub.execute_input":"2023-06-21T16:52:45.278788Z","iopub.status.idle":"2023-06-21T16:57:30.621454Z","shell.execute_reply.started":"2023-06-21T16:52:45.278760Z","shell.execute_reply":"2023-06-21T16:57:30.620162Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Definition of the final CNN model\n\ncnn_model = tf.keras.models.Sequential()\ncnn_model.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, padding=\"same\", activation=\"relu\", input_shape=[28, 28, 1]))\ncnn_model.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2, padding='valid'))\ncnn_model.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, padding=\"same\", activation=\"relu\"))\ncnn_model.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2, padding='valid'))\ncnn_model.add(tf.keras.layers.Flatten())\ncnn_model.add(tf.keras.layers.Dense(units=best_layer_size[0], activation='relu'))\ncnn_model.add(Dropout(best_dropout_rate))\ncnn_model.add(tf.keras.layers.Dense(units=best_layer_size[1], activation='relu'))\ncnn_model.add(Dropout(best_dropout_rate))\ncnn_model.add(tf.keras.layers.Dense(units=26, activation='softmax'))\n\n# compile the model\ncnn_model.compile(optimizer = 'Adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n\nhistory = cnn_model.fit(X_train, y_train, batch_size=best_batch_size, epochs=20,validation_data=(X_test, y_test))\n\n\n# Final evaluation of the model\nscores = cnn_model.evaluate(X_test,y_test, verbose=0)\nprint(\"CNN Error: %.2f%%\" % (100-scores[1]*100))\n\n#Plot fit history\nmodel_fit_history_plot(history)","metadata":{"execution":{"iopub.status.busy":"2023-06-21T16:57:30.623043Z","iopub.execute_input":"2023-06-21T16:57:30.623345Z","iopub.status.idle":"2023-06-21T17:02:35.984438Z","shell.execute_reply.started":"2023-06-21T16:57:30.623322Z","shell.execute_reply":"2023-06-21T17:02:35.983341Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_test = pd.read_csv('/kaggle/input/alphabet/test.csv')","metadata":{"execution":{"iopub.status.busy":"2023-06-21T17:02:35.989168Z","iopub.execute_input":"2023-06-21T17:02:35.989558Z","iopub.status.idle":"2023-06-21T17:02:39.638760Z","shell.execute_reply.started":"2023-06-21T17:02:35.989526Z","shell.execute_reply":"2023-06-21T17:02:39.637881Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_test.shape","metadata":{"execution":{"iopub.status.busy":"2023-06-21T17:02:39.640523Z","iopub.execute_input":"2023-06-21T17:02:39.640912Z","iopub.status.idle":"2023-06-21T17:02:39.648306Z","shell.execute_reply.started":"2023-06-21T17:02:39.640872Z","shell.execute_reply":"2023-06-21T17:02:39.647169Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_test.head(10)","metadata":{"execution":{"iopub.status.busy":"2023-06-21T17:02:39.649396Z","iopub.execute_input":"2023-06-21T17:02:39.649654Z","iopub.status.idle":"2023-06-21T17:02:39.670837Z","shell.execute_reply.started":"2023-06-21T17:02:39.649634Z","shell.execute_reply":"2023-06-21T17:02:39.670045Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#find the rows x columns\ndf_test.columns","metadata":{"execution":{"iopub.status.busy":"2023-06-21T17:02:39.671901Z","iopub.execute_input":"2023-06-21T17:02:39.672187Z","iopub.status.idle":"2023-06-21T17:02:39.686731Z","shell.execute_reply.started":"2023-06-21T17:02:39.672157Z","shell.execute_reply":"2023-06-21T17:02:39.685762Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#check if the first column is target variable?\ny_test = df_test['Unnamed: 0']","metadata":{"execution":{"iopub.status.busy":"2023-06-21T17:02:39.687938Z","iopub.execute_input":"2023-06-21T17:02:39.688241Z","iopub.status.idle":"2023-06-21T17:02:39.698326Z","shell.execute_reply.started":"2023-06-21T17:02:39.688214Z","shell.execute_reply":"2023-06-21T17:02:39.697190Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#first column is not representing the alphabet  and so in the test data set there is target variable column\n#we can safely ignore this variable!\ny_test.unique()","metadata":{"execution":{"iopub.status.busy":"2023-06-21T17:02:39.699992Z","iopub.execute_input":"2023-06-21T17:02:39.700387Z","iopub.status.idle":"2023-06-21T17:02:39.716068Z","shell.execute_reply.started":"2023-06-21T17:02:39.700354Z","shell.execute_reply":"2023-06-21T17:02:39.715150Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create the pandas DataFrame\n#df_result = pd.DataFrame(data, columns=['ID', 'Prediction'])\n#df_result['ID']= df_test['Unnamed: 0']\n\n#remove first column from df_test\ndel df_test['Unnamed: 0'] ","metadata":{"execution":{"iopub.status.busy":"2023-06-21T17:02:39.717427Z","iopub.execute_input":"2023-06-21T17:02:39.718440Z","iopub.status.idle":"2023-06-21T17:02:39.728017Z","shell.execute_reply.started":"2023-06-21T17:02:39.718389Z","shell.execute_reply":"2023-06-21T17:02:39.727143Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#normalization - ADHARSH to test different techniques\nX_test_data = df_test / 255\nX_test_data","metadata":{"execution":{"iopub.status.busy":"2023-06-21T17:02:39.729387Z","iopub.execute_input":"2023-06-21T17:02:39.729738Z","iopub.status.idle":"2023-06-21T17:02:39.887873Z","shell.execute_reply.started":"2023-06-21T17:02:39.729714Z","shell.execute_reply":"2023-06-21T17:02:39.886655Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#convert to numpy array\nX_test_data = np.array(X_test_data)\nX_test_data = X_test_data.reshape(-1,28,28,1)\n# Showing few images\nf, ax = plt.subplots(5,5)\nf.set_size_inches(10,10)\nk = 0\nfor i in range(5):\n    for j in range(5):\n        ax[i,j].imshow(X_test_data[k].reshape(28,28), cmap='gray')\n        k += 1\n    plt.tight_layout()","metadata":{"execution":{"iopub.status.busy":"2023-06-21T17:02:39.889095Z","iopub.execute_input":"2023-06-21T17:02:39.889432Z","iopub.status.idle":"2023-06-21T17:02:44.315168Z","shell.execute_reply.started":"2023-06-21T17:02:39.889390Z","shell.execute_reply":"2023-06-21T17:02:44.314076Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#predict target variable (alphabet) using the CNN model\ny_pred=cnn_model.predict(X_test_data)","metadata":{"execution":{"iopub.status.busy":"2023-06-21T17:02:44.316588Z","iopub.execute_input":"2023-06-21T17:02:44.317096Z","iopub.status.idle":"2023-06-21T17:02:58.911039Z","shell.execute_reply.started":"2023-06-21T17:02:44.317074Z","shell.execute_reply":"2023-06-21T17:02:58.909994Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred.shape","metadata":{"execution":{"iopub.status.busy":"2023-06-21T17:02:58.912528Z","iopub.execute_input":"2023-06-21T17:02:58.912818Z","iopub.status.idle":"2023-06-21T17:02:58.920295Z","shell.execute_reply.started":"2023-06-21T17:02:58.912791Z","shell.execute_reply":"2023-06-21T17:02:58.918930Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"y_pred has 26 columns for all the rows; each column represents the probability of a letter for that row. The next line of code find the the column that has the max value and then puts that column as  value into the predictions variable I think. Adharsh to validate!","metadata":{}},{"cell_type":"code","source":"#creating our predictions using the pixel values; #\n# taking the largest number column value as the result from\npredictions = np.argmax(y_pred,axis = 1)","metadata":{"execution":{"iopub.status.busy":"2023-06-21T17:02:58.921790Z","iopub.execute_input":"2023-06-21T17:02:58.922037Z","iopub.status.idle":"2023-06-21T17:02:58.937733Z","shell.execute_reply.started":"2023-06-21T17:02:58.922015Z","shell.execute_reply":"2023-06-21T17:02:58.936450Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#validate the shape of the predictions\npredictions.shape","metadata":{"execution":{"iopub.status.busy":"2023-06-21T17:02:58.939612Z","iopub.execute_input":"2023-06-21T17:02:58.941803Z","iopub.status.idle":"2023-06-21T17:02:58.948894Z","shell.execute_reply.started":"2023-06-21T17:02:58.941762Z","shell.execute_reply":"2023-06-21T17:02:58.947341Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#convert numpy array to dataframe\ndf_predictions = pd.DataFrame(predictions, columns = ['alphabet'])","metadata":{"execution":{"iopub.status.busy":"2023-06-21T17:02:58.950011Z","iopub.execute_input":"2023-06-21T17:02:58.950421Z","iopub.status.idle":"2023-06-21T17:02:58.959908Z","shell.execute_reply.started":"2023-06-21T17:02:58.950372Z","shell.execute_reply":"2023-06-21T17:02:58.958216Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#replace numbers with alphabet\nalphabet_y_test = df_predictions.replace([0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25], ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M',\n'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z'])","metadata":{"execution":{"iopub.status.busy":"2023-06-21T17:02:58.961909Z","iopub.execute_input":"2023-06-21T17:02:58.962243Z","iopub.status.idle":"2023-06-21T17:02:58.993803Z","shell.execute_reply.started":"2023-06-21T17:02:58.962216Z","shell.execute_reply":"2023-06-21T17:02:58.992670Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#view the predictions\nalphabet_y_test","metadata":{"execution":{"iopub.status.busy":"2023-06-21T17:02:58.994793Z","iopub.execute_input":"2023-06-21T17:02:58.995109Z","iopub.status.idle":"2023-06-21T17:02:59.006188Z","shell.execute_reply.started":"2023-06-21T17:02:58.995077Z","shell.execute_reply":"2023-06-21T17:02:59.005286Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#save to CSV Result\nalphabet_y_test.to_csv('TestDataset_Prediction.csv')","metadata":{"execution":{"iopub.status.busy":"2023-06-21T17:02:59.007265Z","iopub.execute_input":"2023-06-21T17:02:59.007552Z","iopub.status.idle":"2023-06-21T17:02:59.098921Z","shell.execute_reply.started":"2023-06-21T17:02:59.007514Z","shell.execute_reply":"2023-06-21T17:02:59.098124Z"},"trusted":true},"execution_count":null,"outputs":[]}]}